import gradio as gr
import spaces
from gradio_imageslider import ImageSlider
from image_gen_aux import UpscaleWithModel
from image_gen_aux.utils import load_image
import tempfile
import traceback
import cv2  # ë¹„ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€
import numpy as np
from PIL import Image

# --- Model Configuration ---
# ì‚¬ìš©í•  ë‹¨ì¼ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì •ì˜
SINGLE_MODEL_PATH = "4xDF2K_plksr_tiny_fp16_500k.onnx"
SINGLE_MODEL_NAME = "4xDF2K_plksr_tiny_fp16_500k (4x Upscale - ONNX/TensorRT)"

# --- Efficient Model Loading and Caching ---
LOADED_MODELS_CACHE = {}

def get_upscaler(model_path: str):
    """ì§€ì •ëœ ë¡œì»¬ ONNX ëª¨ë¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ Upscaler ê°ì²´ë¥¼ ë¡œë“œí•˜ê³  ìºì‹œí•©ë‹ˆë‹¤."""
    if model_path not in LOADED_MODELS_CACHE:
        print(f"Loading local model: {model_path}")
        try:
            # from_pretrained APIê°€ ë¡œì»¬ íŒŒì¼ ê²½ë¡œë„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ê°€ì •
            # image_gen_aux ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ONNX íŒŒì¼ì„ ë¡œë“œí•  ë•Œ 
            # ONNX Runtimeì„ ì‚¬ìš©í•˜ë©°, í™˜ê²½ì— ë”°ë¼ TensorRTë¥¼ ë°±ì—”ë“œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            upscaler = UpscaleWithModel.from_pretrained(model_path)
            LOADED_MODELS_CACHE[model_path] = upscaler
        except Exception as e:
            # ë¡œì»¬ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ì¶œë ¥
            print(f"Error loading model from path {model_path}: {e}")
            raise gr.Error(f"Failed to load model from {model_path}")

    # to("cuda") í˜¸ì¶œì€ UpscaleWithModel ê°ì²´ê°€ PyTorch ëª¨ë¸ì„ ë¡œë“œí–ˆì„ ë•Œë§Œ ìœ íš¨í•¨
    # ONNX ëª¨ë¸ì€ .to("cuda") ëŒ€ì‹  ONNX Runtime ë°±ì—”ë“œ ì„¤ì •ì„ í†µí•´ GPUë¥¼ ì‚¬ìš©
    return LOADED_MODELS_CACHE[model_path]


# --- Core Upscaling Function (Video) ---
@spaces.GPU
def upscale_video(video_path, progress=gr.Progress(track_tqdm=True)):
    if video_path is None:
        raise gr.Error("No video uploaded. Please upload a video to upscale.")

    try:
        progress(0, desc=f"Loading model: {SINGLE_MODEL_NAME}...")
        upscaler = get_upscaler(SINGLE_MODEL_PATH)
        
        # 1. ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ ì´ˆê¸°í™”
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise gr.Error("Failed to open video file.")

        # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # ì—…ìŠ¤ì¼€ì¼ ë¹„ìœ¨ (ëª¨ë¸ ì´ë¦„ì—ì„œ 4xë¥¼ ê°€ì •)
        scale_factor = 4
        new_width = frame_width * scale_factor
        new_height = frame_height * scale_factor

        # 2. ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ì„¤ì •
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_file:
            output_filepath = temp_file.name
        
        # VideoWriter ê°ì²´ ì´ˆê¸°í™” (MP4 ì»¨í…Œì´ë„ˆ, H.264 ì½”ë± ì‚¬ìš© - FFmpeg í•„ìš”)
        # Note: 'mp4v' (MPEG-4) ë˜ëŠ” 'XVID'ëŠ” ë” ë²”ìš©ì ì¼ ìˆ˜ ìˆì§€ë§Œ, 'H264'ê°€ ê³ í’ˆì§ˆì— ì í•©í•¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v') 
        out = cv2.VideoWriter(output_filepath, fourcc, fps, (new_width, new_height))

        # 3. í”„ë ˆì„ë³„ ì²˜ë¦¬ ë£¨í”„
        processed_frames = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress((processed_frames / frame_count), desc=f"Upscaling frame {processed_frames}/{frame_count}...")
            
            # BGR (OpenCV) -> RGB (PIL) ë³€í™˜
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_frame)

            # ì—…ìŠ¤ì¼€ì¼ë§ ìˆ˜í–‰ (ê¸°ì¡´ ì´ë¯¸ì§€ ë¡œì§ ì¬ì‚¬ìš©, Tiling ìœ ì§€)
            # image_gen_aux ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—¬ê¸°ì„œ TensorRT ì—”ì§„ì„ ì‚¬ìš©í•˜ë„ë¡ ë‚´ë¶€ì ìœ¼ë¡œ ìµœì í™”ë˜ì–´ì•¼ í•¨
            upscaled_pil_image = upscaler(pil_image, tiling=True, tile_width=1024, tile_height=1024)

            # RGB (PIL) -> BGR (OpenCV) ë³€í™˜ ë° ì“°ê¸°
            upscaled_numpy = np.array(upscaled_pil_image)
            bgr_frame = cv2.cvtColor(upscaled_numpy, cv2.COLOR_RGB2BGR)
            out.write(bgr_frame)
            
            processed_frames += 1

        # 4. ìì› í•´ì œ
        cap.release()
        out.release()
        
        # ë¯¸ë¦¬ë³´ê¸°ëŠ” ì²« í”„ë ˆì„ì˜ ì›ë³¸ ë° ì—…ìŠ¤ì¼€ì¼ëœ ë²„ì „ìœ¼ë¡œ ì œê³µ (ì˜µì…˜)
        # ì—¬ê¸°ì„œëŠ” ë³µì¡ì„±ì„ ì¤„ì´ê¸° ìœ„í•´ ë‹¨ìˆœ íŒŒì¼ ì¶œë ¥ë§Œ ë°˜í™˜
        return output_filepath

    except Exception as e:
        print(f"An error occurred: {traceback.format_exc()}")
        raise gr.Error(f"An error occurred during video processing: {e}")

def clear_outputs():
    # ë¹„ë””ì˜¤ ì¶œë ¥ì— ë§ê²Œ ìˆ˜ì •
    return None

# --- Gradio Interface Definition ---
title = f"""<h1 align="center">TensorRT Optimized Video Upscaler ({SINGLE_MODEL_NAME})</h1>
<div align="center">
Upload a video to upscale using the dedicated ONNX model, optimized for GPU performance.<br>
This requires a Google Colab session with **TensorRT**, **FFmpeg**, and **OpenCV** installed.
</div>
"""

with gr.Blocks(delete_cache=(3600, 3600)) as demo:
    gr.HTML(title)
    with gr.Row():
        with gr.Column(scale=1):
            # ğŸ’¡ ì…ë ¥ íƒ€ì…ì„ gr.Videoë¡œ ë³€ê²½
            input_video = gr.Video(label="Input Video (MP4, AVI, etc.)")
            
            # ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´ ëŒ€ì‹  ì‚¬ìš© ëª¨ë¸ ì •ë³´ë¥¼ í‘œì‹œ
            gr.Markdown(f"**ì‚¬ìš© ëª¨ë¸:** `{SINGLE_MODEL_NAME}`")
            
            run_button = gr.Button("Start Video Upscale", variant="primary")
            
        with gr.Column(scale=2):
            # ğŸ’¡ ì´ë¯¸ì§€ ìŠ¬ë¼ì´ë” ëŒ€ì‹  ë¹„ë””ì˜¤ ì¶œë ¥ ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©
            output_video = gr.Video(label="Upscaled Video Output (MP4)")
            
            gr.Markdown(
                "<center><i>Note: The processing time depends heavily on the video length and GPU availability.</i></center>"
            )

    # --- Event Handling ---
    run_button.click(
        fn=clear_outputs,
        inputs=None,
        outputs=[output_video], # ì¶œë ¥ ë³€ê²½
        queue=False 
    ).then(
        fn=upscale_video, # í•¨ìˆ˜ ë³€ê²½
        inputs=[input_video], # ì…ë ¥ ë³€ê²½
        outputs=[output_video],
    )

# --- Pre-load the single model for a faster first-time user experience ---
try:
    print("Pre-loading single model...")
    # ë‹¨ì¼ ëª¨ë¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ë¦¬ ë¡œë“œí•©ë‹ˆë‹¤.
    get_upscaler(SINGLE_MODEL_PATH) 
    print("Model loaded successfully.")
except Exception as e:
    print(f"Could not pre-load the model. The app will still work. Error: {e}")

demo.queue()
demo.launch(share=False)
